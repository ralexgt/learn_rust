[[learning]]  [[programming]]
-> Some operations might take a while to finish, so it would be nice to do something else while waiting for the long running processes to complete
-> Asynchronous programming is an abstraction that lets us express our code in terms of potential pausing points and eventual results that take care of the details of coordinating for us

-> Building on the concepts of threads, parallelism and concurrency, Rust has an alternative approach to writing code: futures, streams and `async` and `await` to express how operations could be asynchronous. More than that, there are third-party crates for that
-> There are operations **bound by the computer's CPU/GPU limit**, such as processing a video and **bound by I/O operations** such as downloading a video from a network
-> The OS provides a certain amount of interruptions to provide concurrency. However, that interruption happens on the entire program, to let other programs run
-> We can avoid blocking the main thread by spawning a dedicated thread to download each file. ***HOWEVER*** the significant overhead of the system resources used by those threads would eventually become a problem
-> We would prefer if we could have calls that didn't block in the first plance, instead define a number of tsks that we'd like our program to complete and allow the runtime to choose the best order and manner in which to run them

## Parallelism vs. Concurrency
-> Concurrency - can think about having 2 projects in progress. You work on project A, when you get bored or get stuck you switch to project B and so on
-> Parallelism - splitting out project A to me and project B to some other team member
-> Parallelism and concurrency can also meet. If the team member is stuck on his project, you can go help him.
-> Projects might also be dependent on one another at some points, creating serial/secvential parts of the code

-> Rust async code happens concurrently. Depending on hardware, OS ad the async runtime, that concurrency mai also use parallelism under the hood

# Futures and the Async Syntax
-> futures and `async` and `await`
-> A future is a value that may not be ready now but will become ready at some point in the future (same concept as promises in js)
-> Rust provides a `Future` trait as a building block so that different data structures can implement different async operations but with a common interface
-> Futures re types that implement the `Future` trait
-> Each future holds its own information about the progress made and what "ready" means
-> `async` keyword is used for blocks and functions to specify that they can be interrupted and resumed. Within an `async` block or fn you can use the `await` keyowrd to *await* for a future to become ready
-> Any point where you await a future within an async block or fn is a potential spot for that block or fn to pause and resume
-> ***polling*** is the process of checking with a future to see if its value is available yet

-> For programs in this chapters we used `trpl` crate (the rust programming language) that under the hood re-exports `futures` - a Rust official crate for experimental async code and `tokio` - the most widely use async runtime in Rust, especially for web. There are different async runtimes for differnet scenarios

-> Rust futures are **lazy**. Meaning they won't do anything until you explicitely tell them with `.await`

-> We can not use `async fn main`
	-> Async needs an async runtime and main can initialize runtimes, but it is not in itself a runtime

# Concurrency with Async
-> Differences between `threads` and `futures`
-> Async APIs usually offer an interface for tasks spawn and sleep, like the threads one
-> We might have to wrap the main function in a `block_on` function that takes a future (block of code with `async`), in order to have an `async runtime`
-> We can also create handles for async functions, just like for threads. Difference is that we can use `::join().await` to wait and get the result of multiple futures, and we will get a tuple with each of the futures result
-> With `future joins` you will see the same result every time. This is because it is `fair`, meaning it checks each future as often sa the other, unlike `threads` where it is up to the OS
-> `await` on an async block directly wait for the block to finish

-> Sending data is similar to threads, but they use APIs from async crates
-> Sending data with an async block is essentially liniar
-> To get proper asynchronous behavior, we will put `tx` in an async block, recieving a future and rx in an async block receiving another future. Then we will join the together and await the join operation. This will essentially mean that those 2 blocks will run concurrently
-> You can use `join` the function to join 2 futures or `join!` the macro to join multiple futures

# Yielding control to the runtime
-> Up until now we would give the chance to the async runtime to run another future whenever we had an `await`. The inverse is also true, we would have synchronous block until that `await`. So if we do a lot of computation without an `await`, we essentially block the entire thread for a long time. ***Future starving other futures***
-> To avoid starvation, we could sleep the future for a bit and `await` so that the runtime gets control and chooses which future will run from that point. However, sleeping involves exactly dead time, what we are trying to avoid.
-> `yield_now` is exactly what we need. The function essentially tells the runtime: take control from here nad decide what runs next

# Streams: Future in Sequence
-> The `recv` method produces a sequence of items over time. This is an instance of a much more general pattern known as a stream
-> Streams are futures, we can use them with any other kind of future and combine them in different ways
-> For example, we can batch up events to avoid triggering too many network calls, set timeouts on sequences of long-runing operations or throttle user iterface events to avoid doing needless work
-> An example of sequence of items is the Iterator trait with its `.next()` method. Still there are 2 differences between iterators and the async channel receiver
	-> Iterators are synchronous, while channel receiver is asynchronous
	-> The second difference is their APIs, we use either `next` or `recv`
-> We can create streams from iterators usually with something like `stream_from_iter(iterator)`
-> To use `.next` on an interator from a stream we need to bring in scope `StreamExt`, an extension on the trait `Stream`. While `Stream` defines a low-level interface that combines the `Iterator` and `Future` traits, `StreamExt` supplies a higher-level set of APIs on top of `Stream`, including the `next` method

# The Async Trait
-> Rust defines the `Future` trait with a `type Output` and a `fn poll`
-> The future's associated type `Output` says what the Future resolves to
-> The `poll` method takes a special `Pin` reference for its `self` parameter and a mutable reference to a `Context` type and returns a `Poll<Self::Output>`
-> `Poll` is an enum with 2 varaints: `Ready` and `Pending`
-> When we use `await` in Rust code, the compiler uses `poll` under the hood
-> The runtime `polls` each future it is responsible for, putting the future back to sleep when it is not yet ready

-> We used `join!` to await 3 futures, however it is often that we will use `join!` to wait on a collection such as a vector with some number of futures that won't be known until runtime
-> We can make a vector of trait objects `Vec<Box<dyn Future<Output = ()>>>` so we can have all the items in the vector be of the same type
-> Using `join_all` on that vector won't run each future, instead create a new struct `JoinAll`
-> The compiler implements `Unpin` automatically for all types where it can prove it is safe. Because our Vec of boxes might have internal references that would not be safe, it does not automatically implement `Unpin`. Instead of `Box` we will use `Pin` from `std::pin` and we will also have to wrap our `async` blocks in the `pin!` macro to be adjusted to the trait object type `Pin`
-> `Pin` and `Unpin` are generally used in low-level async code or runtime development. Still, you might see them in day by day Rust code every now and then and it helps knowing about them so you have a starting point for solving the issue

-> The `Stream` trait
-> At this point, `Stream` is not in the standard library yet, but it has a common implementation across other crates. It has an associated type `Item` and a function `poll_next`
-> In addition, `StreamExt` provides other methods such as `next()`

# Futures, Tasks and Threads all together
-> Threads provide one approach to concurreny. Another approach is using futures and streams. The answer to which one to use, usually, is *both*
-> Threads use a fair bit of memory for each thread, also they are an option only with the OS and hardware supports them. Some embedded systems don't have an OS at all, so no threads :(
-> Async has a different and *complementary* set of tradeoffs. Concurrent operations don't require their own threads, they can run on tasks as with `spawn_task`. A task is like a thread, but instead of being managed by the OS, it is managed by library-level code: the runtime
-> Async tasks aren't always better than threads and vice versa. Concurrency with threads is in some ways a simple programming model and this can be a strength or a weakness. Threads are ***fire and forget***. We can not interrupt them like we do with futures and they run to completion unless interrupted by the OS itself
-> Actually threads and tasks work very well together. `spawn_blocking` and `spawn_task` functions are multithreaded by default. Many runtimes use an approach called `work stealling` to move tasks around between threads, based on how the threads are being currently utilized

-> Some rules of thumb:
	-> If the work is very parallelizable (CPU-bound) such as processing a bunch of data where each part can be processed separately, threads are a better choice
	-> If the work is very concurrent (I/O-bound) such as handling messages from a bunch of different sources that may come in at different intervals or different rates, async is a better choice
	-> You can also mix them together, for example spawning a thread to send values through an async channel and having an async `block_on` to receive those values in the receiver `rx`