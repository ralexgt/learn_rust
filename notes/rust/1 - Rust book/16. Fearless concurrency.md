[[learning]]  [[programming]]
-> Concurrent = Different parts of a program execute idependently
-> Parallel = Different parts of a program execute at the same time
-> Rust leverages ownership and type checking to bring concurrency errors at compile-time, rather than runtime when it would be way harder to catch
-> The point is to fix your code while you work on it, rather then after it has been shipped
-> For this chapter, for simplicity, *concurrent* is used for *concurent and/or parallel*                                                                                                                                                     
	-> Threads to run multiple pieces of code at the same time
	-> Message-passing concurrency, where channels send messages between threads
	-> Shared-state concurrency, where multiple threads have access to some piece of data
	-> `Sync` and `Send` traits to extend Rust's concurrency guarantees to user-defined types as well as types provided by the standard library

# Using Threads
-> In most operating systems, an executed program's code is run in a process and the OS will manage multiple processes at once
-> Within a program you can also have independent parts that run simultaneously
-> The features that run these independent parts are called ***threads***. Ex: a web server could have multiple threads so that it can respond to more than one request at the same time
-> Splitting the workload into multiple threads can improve performance, but it also adds complexity
-> Because threads run simultaneously, there's no inherent guarantee about the order in which parts of your code on different threads will run, leading to problems such as race conditions, deadlocks, hard to reproduce bugs
-> Rust standard library uses a 1:1 model of thread implementation
	-> A program uses one OS thread per one language thread
	-> ThRust's async and other crates implement other models of threading that make different trade-offs to the 1:1 model
## Thread `spawn`
-> `thread::spawn` takes a closule containing the code we want to run in the new thread
-> `thread::sleep` forces the thread to stop its execution for a specific duration, allwoing a different thread to run
-> The order in which threads run is dependent on how the OS schedules the threads and we do not have much to say in this matter
-> To avoid the program exiting before a thread can run, we can assign the thread to a variable, conventionally a `handle` then `join` it with a main thread
-> Said variable will be a `JoinHandle<T>` with `T` being the type that the thread returns
-> `handle.join()` waits for the thread to finish and returns a `Result`
	-> The completion of the thread is synchronized with this function, so it won't return before the thread is done
	-> If the thread `panics`, this method will return an `Err` with the error
	-> Returns `Result<T>`, where `T` is substituted for `T, std::err::Err` and `T` here is the type that the thread returns
## `move` Closures with Threads
-> We often want the closure in `thread::spawn` to take ownership of the values it uses from the environment, transfering ownership of values from one thread to another
-> If we don't specify the variables captured from the outside environment and just use them in the thread, Rust will **infer** how to pass them and usually tries to just borrow them. Rust can't tell how long a thread will run, so it doesnt know whether the reference to the variable will always be valid
-> To avoid Rust's `infered` behaviour we can use `move ||` to start the closure. This will make sure that we `move` all variables captured from the outside environment. This will give ownership of the value to the thread

# Message Passing between threads
-> One popular way to ensure safe concurrency is message passing between threads
-> Rust standard library provides an implementation of channels
-> A *channel* is a general programming concept by which data is sent from one thread to another
-> A channel has two halves: a transmitter and a receiver
-> The transmitter is the upstream, the receiver is the downstream location
-> In practice, one part of your code would call a methods on the transmitter with the data you want to send and another part check the receiving end for arriving messages
-> A channel is **closed** if either the transmitter or receiver is dropped
-> There are multiple types of channels. One of the is `mpsc` (multiple producers single consumer). It is implemented as a FIFO. You can found it in `std::sync`
-> Sending a value through the channel first gives ownership to the method `send()`, then it transfers to the variable that receives it with `recv`
-> `tx.clone()` creates one more transmitter

# Shared-State Concurrency
-> Message passing is a totally fine way to handle concurrency, however there are multiple ways
-> Another way is for multiple threads to access the same shared data
-> Shared-memory concurrency is like multiple ownership: multiple threads can access the same memory location at the same time
### Controlling access with mutexes
-> mutual exclusion - mutexes allow only one thread to access some data at any given time
-> To access the data in a mutex, a thread must first signal that it wants access by asking to acquire the mutex's lock
-> The `lock` is a data structure that is part of the mutex that keeps track of who currently has exclusive access to the data
-> `Mutex<T>` API

# `Send` and `Sync` traits
-> The `Send` marker trait indicates that ownership of values of the type implementing `Send` can be transferred between threads
-> Any type composed entirely of `Send` types is automatically marked as `Send`

-> The `Sync` marker trait indicates that it is safe for the type implementing `Sync` to be referenced from multiple threads
-> Any type composed entirely of `Sync` types is automatically marked as `Sync`
 types is automatically marked as `Sync`
  types is automatically marked as `Sync`

-> Market traits do not have any methods to implement. They are just useful for enforcing invariants related to concurrency

-> Manually implementing those traits involves unsafe Rust code